{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM, Dropout\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import sys\n",
        "import heapq\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 5\n",
        "\n",
        "path = '1661-0.txt'\n",
        "text = open(path, encoding='utf-8').read().lower()\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "\n",
        "SEQUENCE_LENGTH = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - SEQUENCE_LENGTH, step):\n",
        "    sentences.append(text[i: i + SEQUENCE_LENGTH])\n",
        "    next_chars.append(text[i + SEQUENCE_LENGTH])\n",
        "print(len(sentences))\n",
        "\n",
        "X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(\"gere\")\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, y, validation_split=0.05, batch_size=128, epochs=10, shuffle=True).history\n",
        "\n",
        "model.save('keras_model.h5')\n",
        "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
        "\n",
        "model = load_model('keras_model.h5')\n",
        "history = pickle.load(open(\"history.p\", \"rb\"))\n",
        "\n",
        "def prepare_input(text):\n",
        "    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
        "    for t, char in enumerate(text):\n",
        "        x[0, t, char_indices[char]] = 1.\n",
        "        \n",
        "    return x\n",
        "\n",
        "def sample(preds, top_n=3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    \n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)\n",
        "\n",
        "\n",
        "def predict_completion(text):\n",
        "    original_text = text\n",
        "    generated = text\n",
        "    completion = ''\n",
        "    while True:\n",
        "        x = prepare_input(text)\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds, top_n=1)[0]\n",
        "        next_char = indices_char[next_index]\n",
        "        text = text[1:] + next_char\n",
        "        completion += next_char\n",
        "        \n",
        "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
        "            return completion\n",
        "\n",
        "def predict_completions(text, n=3):\n",
        "    x = prepare_input(text)\n",
        "    #print(\"gf\")\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    #print(\"fg\")\n",
        "    next_indices = sample(preds, n)\n",
        "    #print(text)\n",
        "    #print(predict_completion(text[1:]))\n",
        "#     print(indices_char[16]+predict_completion(text[1:]+indices_char[16]))\n",
        "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "quotes = [\n",
        "    \"It is not a lack of love, but a lack of friendship that makes unhappy marriages.\",\n",
        "    \"That which does not kill us makes us stronger.\",\n",
        "    \"I'm not upset that you lied to me, I'm upset that from now on I can't believe you.\",\n",
        "    \"And those who were seen dancing were thought to be insane by those who could not hear the music.\",\n",
        "    \"It is hard enough to remember my opinions, without also remembering my reasons for them!\"\n",
        "]\n",
        "\n",
        "\n",
        "for q in quotes:\n",
        "    seq = q[:40].lower()\n",
        "    print(seq)\n",
        "    print(predict_completions(seq, 5))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_mb09ELW4WN",
        "outputId": "d39ffc81-4056-4e8d-d656-0d0df4863be1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length: 581888\n",
            "193950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gere\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1440/1440 [==============================] - 203s 139ms/step - loss: 1.9814 - accuracy: 0.4190 - val_loss: 2.1107 - val_accuracy: 0.4105\n",
            "Epoch 2/10\n",
            "1440/1440 [==============================] - 192s 134ms/step - loss: 1.6265 - accuracy: 0.5128 - val_loss: 2.0326 - val_accuracy: 0.4437\n",
            "Epoch 3/10\n",
            "1440/1440 [==============================] - 185s 128ms/step - loss: 1.5213 - accuracy: 0.5423 - val_loss: 2.0281 - val_accuracy: 0.4483\n",
            "Epoch 4/10\n",
            "1440/1440 [==============================] - 192s 134ms/step - loss: 1.4675 - accuracy: 0.5554 - val_loss: 2.0255 - val_accuracy: 0.4595\n",
            "Epoch 5/10\n",
            "1440/1440 [==============================] - 188s 131ms/step - loss: 1.4319 - accuracy: 0.5656 - val_loss: 2.0250 - val_accuracy: 0.4604\n",
            "Epoch 6/10\n",
            "1440/1440 [==============================] - 188s 131ms/step - loss: 1.4081 - accuracy: 0.5717 - val_loss: 2.0191 - val_accuracy: 0.4603\n",
            "Epoch 7/10\n",
            "1440/1440 [==============================] - 193s 134ms/step - loss: 1.3875 - accuracy: 0.5779 - val_loss: 2.0110 - val_accuracy: 0.4640\n",
            "Epoch 8/10\n",
            "1440/1440 [==============================] - 198s 138ms/step - loss: 1.3720 - accuracy: 0.5803 - val_loss: 2.0322 - val_accuracy: 0.4616\n",
            "Epoch 9/10\n",
            "1440/1440 [==============================] - 201s 140ms/step - loss: 1.3582 - accuracy: 0.5847 - val_loss: 2.0358 - val_accuracy: 0.4600\n",
            "Epoch 10/10\n",
            "1440/1440 [==============================] - 196s 136ms/step - loss: 1.3465 - accuracy: 0.5871 - val_loss: 2.0341 - val_accuracy: 0.4585\n",
            "it is not a lack of love, but a lack of \n",
            "['the ', 'a ', 'my ', 'his ', 'some ']\n",
            "\n",
            "that which does not kill us makes us str\n",
            "['eet ', 'uck ', 'ange ', 'onge ', 'ick ']\n",
            "\n",
            "i'm not upset that you lied to me, i'm u\n",
            "['nderstand ', 'se ', 'pon ', 'm, ', 't ']\n",
            "\n",
            "and those who were seen dancing were tho\n",
            "['ught ', 'se ', 'ne ', 'me ', 're ']\n",
            "\n",
            "it is hard enough to remember my opinion\n",
            "[' of ', '.”\\n\\n“i ', 's ', ', ', 'al ']\n",
            "\n"
          ]
        }
      ]
    }
  ]
}